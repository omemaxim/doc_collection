# AUTOGENERATED! DO NOT EDIT! File to edit: 00_search.ipynb (unless otherwise specified).

__all__ = ['index_data', 'index_batch', 'embed_text', 'query']

# Cell
from elasticsearch import Elasticsearch, helpers
from sentence_transformers import SentenceTransformer
import string

# Cell
def index_data(d, es, model, INDEX_NAME='my_index_name', BATCH_SIZE=5000):
    '''indexes data'''

    print("Creating the " + INDEX_NAME + " index.")

    es.indices.delete(index=INDEX_NAME, ignore=[404])

    settings = {
            "settings": {
                "number_of_shards": 2,
                "number_of_replicas": 1
            },
            "mappings": {
                "dynamic": "true",
                "_source": {
                "enabled": "true"
                },
                "properties": {
                    "text": {
                        "type": "text"
                    },
                    "name": {
                        "type": "text"
                    },
                    "library": {
                        "type": "text"
                    },
                    "text_vector": {
                        "type": "dense_vector",
                        "dims": 768
                    }
                }
            }
        }

    es.indices.create(index=INDEX_NAME, body=settings)

    docs = []
    count = 0

    for ind in d.index:
        doc = {'_id': ind,
               'text': d.text[ind],
               'name': d.name[ind],
               'library': d.library[ind],
               'text_vector': embed_text(d.text[ind], model)}
        docs.append(doc)
        count += 1

        if count % BATCH_SIZE == 0:
            index_batch(docs)
            docs = []
            print("Indexed {} documents.".format(count))

    if docs:
        index_batch(docs)
        print("Indexed {} documents.".format(count))

# Cell
def index_batch(docs):
    print("Starting embeddings")

    requests = []
    for i, doc in enumerate(docs):
        request = doc
        request["_op_type"] = "index"
        request["_index"] = INDEX_NAME
        requests.append(request)

    helpers.bulk(es, requests)

# Cell
def embed_text(text, model):
    """embedds text"""

    text = text.lower()
    text = text.translate(str.maketrans('', '', string.punctuation))

    return model.encode(text)

# Cell
def query(text, size, es, model, INDEX_NAME='my_index_name', field=None):
    '''Elasticsearch query function'''

    query_vector = embed_text(text, model)

    script_query = {
        "script_score": {
            "query": {"match_all": {}},
            "script": {
                "source":
                """
                    cosineSimilarity(params.query_vector, 'text_vector') + 1.0
                """,
                 "params": {"query_vector": query_vector}
            }
        }
    }

    response = es.search(
        index=INDEX_NAME,
        body={
            "size": size,
            "query": script_query,
            "_source": {"includes": ['name', 'text']} # source fields to appear in response
        }
    )

    if field != None:
        return [doc['_source'][field] for num, doc in enumerate(response['hits']['hits'])]


    return response