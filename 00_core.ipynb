{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc_collection\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import json\n",
    "import pkg_resources\n",
    "import pkgutil\n",
    "import pandas\n",
    "import warnings\n",
    "import pydoc\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def replace(list_, str1, str2):\n",
    "    i = list_.index(str1)\n",
    "    return list_[:i] + [str2] + list_[i + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_top_hundred():\n",
    "    if not os.path.isfile('data/top.json'):\n",
    "        os.system('curl -X GET \"https://hugovk.github.io/top-pypi-packages/top-pypi-packages-30-days.json\" > data/top.json')\n",
    "        \n",
    "    f = open('data/top.json')\n",
    "    data = json.load(f)\n",
    "    \n",
    "    return [dictionary['project'] for dictionary in data['rows'][:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  280k  100  280k    0     0   387k      0 --:--:-- --:--:-- --:--:--  387k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['boto3',\n",
       " 'botocore',\n",
       " 'urllib3',\n",
       " 'setuptools',\n",
       " 'requests',\n",
       " 's3transfer',\n",
       " 'six',\n",
       " 'python-dateutil',\n",
       " 'certifi',\n",
       " 'idna',\n",
       " 'pyyaml',\n",
       " 'typing-extensions',\n",
       " 'charset-normalizer',\n",
       " 'pip',\n",
       " 'numpy',\n",
       " 'google-api-core',\n",
       " 'wheel',\n",
       " 'cryptography',\n",
       " 'pyparsing',\n",
       " 'packaging',\n",
       " 'jmespath',\n",
       " 'awscli',\n",
       " 'rsa',\n",
       " 'pyasn1',\n",
       " 'importlib-metadata',\n",
       " 'zipp',\n",
       " 'pyjwt',\n",
       " 'colorama',\n",
       " 'pytz',\n",
       " 'click',\n",
       " 'pandas',\n",
       " 'protobuf',\n",
       " 'attrs',\n",
       " 'cffi',\n",
       " 'oauthlib',\n",
       " 'jinja2',\n",
       " 'requests-oauthlib',\n",
       " 'markupsafe',\n",
       " 'pycparser',\n",
       " 'docutils',\n",
       " 'google-auth',\n",
       " 'cachetools',\n",
       " 'pyasn1-modules',\n",
       " 'wrapt',\n",
       " 'googleapis-common-protos',\n",
       " 'psutil',\n",
       " 'isodate',\n",
       " 'pyarrow',\n",
       " 'sqlalchemy',\n",
       " 'azure-core',\n",
       " 'lxml',\n",
       " 'chardet',\n",
       " 'tomli',\n",
       " 'msrest',\n",
       " 'async-timeout',\n",
       " 'grpcio',\n",
       " 'decorator',\n",
       " 'aiobotocore',\n",
       " 'werkzeug',\n",
       " 'pillow',\n",
       " 'aiohttp',\n",
       " 'multidict',\n",
       " 'beautifulsoup4',\n",
       " 'soupsieve',\n",
       " 'scipy',\n",
       " 'yarl',\n",
       " 'google-cloud-storage',\n",
       " 'py',\n",
       " 'fsspec',\n",
       " 'google-cloud-bigquery',\n",
       " 'importlib-resources',\n",
       " 'pytest',\n",
       " 'greenlet',\n",
       " 'azure-storage-blob',\n",
       " 'jsonschema',\n",
       " 'pluggy',\n",
       " 'tqdm',\n",
       " 'pyopenssl',\n",
       " 'platformdirs',\n",
       " 's3fs',\n",
       " 'tabulate',\n",
       " 'frozenlist',\n",
       " 'aiosignal',\n",
       " 'asn1crypto',\n",
       " 'pyrsistent',\n",
       " 'toml',\n",
       " 'filelock',\n",
       " 'flask',\n",
       " 'websocket-client',\n",
       " 'google-cloud-core',\n",
       " 'google-resumable-media',\n",
       " 'future',\n",
       " 'azure-common',\n",
       " 'scikit-learn',\n",
       " 'pygments',\n",
       " 'itsdangerous',\n",
       " 'openpyxl',\n",
       " 'et-xmlfile',\n",
       " 'psycopg2-binary',\n",
       " 'iniconfig']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_hundred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def pip_top_hundred():\n",
    "    lib_names = get_top_hundred()\n",
    "    lib_names = replace(lib_names, 'msrest', 'msrestazure')\n",
    "    for lib_name in lib_names:\n",
    "        os.system('pip install ' + lib_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def val(key):\n",
    "    return key[0] != '_' and key[-1] != '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def extr(module_name):\n",
    "    names = []\n",
    "    texts = []\n",
    "    paths = []\n",
    "    \n",
    "    finded_names, finded_texts, finded_paths = recclass(module_name, module_name.__name__)\n",
    "    names.extend(finded_names)\n",
    "    texts.extend(finded_texts)\n",
    "    paths.extend(finded_paths)\n",
    "            \n",
    "    if hasattr(module_name, '__path__'):\n",
    "        file = module_name.__path__\n",
    "    else:\n",
    "        file = [inspect.getfile(module_name)]\n",
    "        \n",
    "    for importer, key, ispkg in pkgutil.iter_modules(file): \n",
    "        if val(key) and ispkg and hasattr(module_name, key):\n",
    "            if key != module_name.__name__ and fullname(getattr(module_name, key)).startswith(fullname(module_name)):\n",
    "                finded_names, finded_texts, finded_paths = extr(getattr(module_name, key))\n",
    "                names.extend(finded_names)\n",
    "                texts.extend(finded_texts)\n",
    "                paths.extend(finded_paths)\n",
    "                \n",
    "    return names, texts, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "def recclass(cl, path):\n",
    "    names = []\n",
    "    texts = []\n",
    "    paths = []\n",
    "    \n",
    "    names.append(cl)\n",
    "    texts.append(pydoc.render_doc(cl, renderer=pydoc.TextDoc()))\n",
    "    paths.append(path)\n",
    "    \n",
    "    for key_, value_ in inspect.getmembers(cl, inspect.isroutine):\n",
    "        if val(key_) and hasattr(cl, key_):\n",
    "            names.append(getattr(cl, key_))\n",
    "            texts.append(pydoc.render_doc(getattr(cl, key_), renderer=pydoc.TextDoc()))\n",
    "            paths.append(path + '.' + key_)\n",
    "    \n",
    "    for key_, value_ in inspect.getmembers(cl, inspect.isfunction):\n",
    "        if val(key_) and hasattr(cl, key_):\n",
    "            names.append(getattr(cl, key_))\n",
    "            texts.append(pydoc.render_doc(getattr(cl, key_), renderer=pydoc.TextDoc()))\n",
    "            paths.append(path + '.' + key_)\n",
    "               \n",
    "    for key_, value_ in inspect.getmembers(cl, inspect.isdatadescriptor): \n",
    "        if val(key_) and hasattr(cl, key_):\n",
    "            names.append(getattr(cl, key_))\n",
    "            texts.append(pydoc.render_doc(getattr(cl, key_), renderer=pydoc.TextDoc()))\n",
    "            paths.append(path + '.' + key_)\n",
    "             \n",
    "    for key_, value_ in inspect.getmembers(cl, inspect.isclass): \n",
    "        if val(key_) and hasattr(cl, key_):\n",
    "            if fullname(getattr(cl, key_)).startswith(fullname(cl)):\n",
    "                finded_names, finded_texts, finded_paths = recclass(getattr(cl, key_), path + '.' + key_)\n",
    "                names.extend(finded_names)\n",
    "                texts.extend(finded_texts)\n",
    "                paths.extend(finded_paths)\n",
    "                \n",
    "    return names, texts, paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def fullname(o):\n",
    "    \n",
    "    if inspect.ismodule(o):\n",
    "        return o.__name__\n",
    "    \n",
    "    if inspect.isfunction(o) or inspect.isclass(o) or inspect.ismethod(o):\n",
    "        return o.__module__ + '.' + o.__name__\n",
    "    \n",
    "    if inspect.isroutine(o):\n",
    "        if hasattr(o, '__name__'):\n",
    "            return o.__class__.__module__ + '.' + o.__name__\n",
    "        else:\n",
    "            return o.__class__.__module__ + '.' + o.__class__.__name__\n",
    "        \n",
    "    if inspect.isdatadescriptor(o):\n",
    "        if o.__class__.__name__ == 'property' and o.fget != None:\n",
    "            if o.fget.__module__ != None:\n",
    "                return o.fget.__module__ + '.' + o.fget.__name__ \n",
    "            else:\n",
    "                return o.fget.__name__\n",
    "        else:\n",
    "            return o.__class__.__module__ + '.' + o.__class__.__name__\n",
    "        \n",
    "    return o.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "    \n",
    "    installed_packages = pkg_resources.working_set\n",
    "    installed_packages_list = sorted([\"%s\" % i.key for i in installed_packages])\n",
    "    \n",
    "    installed_packages_list.remove('transformers')\n",
    "    \n",
    "    unsolved_package_names = ['beautifulsoup4', 'typing-extensions', 'pyyaml', 'argon2-cffi', 'jupyter-client', 'jupyter-core']\n",
    "    unsolved_import_names = ['bs4', 'typing', 'yaml', 'argon2', 'jupyter_client', 'jupyter_core']\n",
    "    \n",
    "    for i in range(len(unsolved_package_names)):\n",
    "        installed_packages_list = replace(installed_packages_list, unsolved_package_names[i], unsolved_import_names[i])\n",
    "        \n",
    "    names = []\n",
    "    texts = []\n",
    "    paths = []\n",
    "    \n",
    "    c = 0\n",
    "    for lib_name in installed_packages_list:\n",
    "        try:\n",
    "            importlib.import_module(lib_name)\n",
    "        \n",
    "            finded_names, finded_texts, finded_paths = extr(sys.modules[lib_name])\n",
    "            names.extend(finded_names)\n",
    "            texts.extend(finded_texts)\n",
    "            paths.extend(finded_paths)\n",
    "            \n",
    "            print(len(names) - c, 'files from', lib_name, 'added')\n",
    "            c = len(names)\n",
    "            \n",
    "        except Exception:\n",
    "            try:\n",
    "                metadata_dir = pkg_resources.get_distribution(lib_name).egg_info\n",
    "                for name in open('%s/%s' % (metadata_dir, 'top_level.txt')).read().rstrip().split('\\n'):\n",
    "                    if name != '' and val(name):\n",
    "                        importlib.import_module(name)\n",
    "            \n",
    "                        finded_names, finded_texts, finded_paths = extr(sys.modules[name])\n",
    "                        names.extend(finded_names)\n",
    "                        texts.extend(finded_texts)\n",
    "                        paths.extend(finded_paths)\n",
    "            \n",
    "                        print(len(names) - c, 'files from', name, 'added')\n",
    "                        c = len(names)\n",
    "                    \n",
    "            except Exception:\n",
    "                print('--------------- error during ' + lib_name + ' documentation extracting')\n",
    "                \n",
    "    doc = pandas.DataFrame({'text': texts, 'path': paths})\n",
    "    doc_wo_dupl = doc.drop_duplicates(subset=['text'])\n",
    "    d = doc_wo_dupl.groupby('text').agg(paths = ('path', lambda x: list(x)), library = ('path', lambda x: list(x)[0].split('.')[0])).reset_index()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 files from absl added\n",
      "41 files from adal added\n",
      "1 files from aiobotocore added\n",
      "709 files from aiohttp added\n",
      "59 files from aioitertools added\n",
      "15 files from aiosignal added\n",
      "33 files from argon2 added\n",
      "1 files from asgiref added\n",
      "3 files from asn1crypto added\n",
      "35 files from asttokens added\n",
      "25 files from astunparse added\n",
      "12 files from async_generator added\n",
      "16 files from async_timeout added\n",
      "29 files from attrs added\n",
      "1 files from awscli added\n",
      "1 files from azure added\n",
      "1 files from azure added\n",
      "1 files from azure added\n",
      "3 files from backcall added\n",
      "20 files from backports.zoneinfo added\n",
      "2215 files from bs4 added\n",
      "35 files from beir added\n",
      "11 files from bleach added\n",
      "85 files from boto3 added\n",
      "117 files from botocore added\n",
      "198 files from cachetools added\n",
      "5 files from certifi added\n",
      "90 files from cffi added\n",
      "16 files from chardet added\n",
      "124 files from charset_normalizer added\n",
      "628 files from click added\n",
      "30 files from colorama added\n",
      "417 files from cryptography added\n",
      "18 files from cycler added\n",
      "1491 files from datasets added\n",
      "22 files from debugpy added\n",
      "28 files from decorator added\n",
      "18 files from defusedxml added\n",
      "98 files from dill added\n",
      "6 files from django added\n",
      "27 files from docutils added\n",
      "1101 files from elasticsearch added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 15:36:29.319963: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-27 15:36:29.320250: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 files from eli5 added\n",
      "83 files from entrypoints added\n",
      "2 files from et_xmlfile added\n",
      "1 files from execnb added\n",
      "30 files from executing added\n",
      "8255 files from faiss added\n",
      "1 files from fastcore added\n",
      "290 files from fastjsonschema added\n",
      "50 files from filelock added\n",
      "473 files from flask added\n",
      "146 files from flatbuffers added\n",
      "4 files from fontTools added\n",
      "49 files from frozenlist added\n",
      "190 files from fsspec added\n",
      "1 files from future added\n",
      "126 files from gast added\n",
      "4 files from google added\n",
      "4 files from google added\n",
      "3 files from google_auth_oauthlib added\n",
      "48 files from google added\n",
      "48 files from google added\n",
      "48 files from google added\n",
      "48 files from google added\n",
      "14 files from google_crc32c added\n",
      "7 files from pasta added\n",
      "48 files from google added\n",
      "48 files from google added\n",
      "197 files from graphviz added\n",
      "21 files from greenlet added\n",
      "522 files from grpc added\n",
      "1 files from grpc_status added\n",
      "77 files from h11 added\n",
      "236 files from h5py added\n",
      "251 files from huggingface_hub added\n",
      "43 files from idna added\n",
      "260 files from importlib_metadata added\n",
      "28 files from importlib_resources added\n",
      "18 files from iniconfig added\n",
      "5 files from install added\n",
      "149 files from ipykernel added\n",
      "1470 files from IPython added\n",
      "1 files from ipython_genutils added\n",
      "10050 files from ipywidgets added\n",
      "37 files from isodate added\n",
      "158 files from itsdangerous added\n",
      "1306 files from jedi added\n",
      "233 files from jinja2 added\n",
      "6 files from jmespath added\n",
      "168 files from joblib added\n",
      "170 files from jsonschema added\n",
      "1 files from jupyter added\n",
      "1604 files from jupyter_client added\n",
      "1 files from jupyter_console added\n",
      "4 files from jupyter_core added\n",
      "2 files from jupyterlab_pygments added\n",
      "1 files from jupyterlab_widgets added\n",
      "26273 files from keras added\n",
      "5 files from keras_preprocessing added\n",
      "50 files from kiwisolver added\n",
      "1 files from clang added\n",
      "222 files from lightgbm added\n",
      "3 files from lxml added\n",
      "53 files from markdown added\n",
      "95 files from markupsafe added\n",
      "201 files from matplotlib added\n",
      "1 files from matplotlib_inline added\n",
      "177 files from mistune added\n",
      "218 files from msrest added\n",
      "10 files from msrestazure added\n",
      "188 files from multidict added\n",
      "73 files from multiprocess added\n",
      "128 files from nbclient added\n",
      "3938 files from nbconvert added\n",
      "380 files from nbdev added\n",
      "214 files from nbformat added\n",
      "6 files from nest_asyncio added\n",
      "7703 files from nltk added\n",
      "3 files from notebook added\n",
      "7299 files from numpy added\n",
      "1670 files from oauthlib added\n",
      "2896 files from cv2 added\n",
      "930 files from openpyxl added\n",
      "41 files from opt_einsum added\n",
      "31 files from outcome added\n",
      "1 files from packaging added\n",
      "6900 files from pandas added\n",
      "87 files from pandocfilters added\n",
      "23 files from parso added\n",
      "114 files from pexpect added\n",
      "39 files from pickleshare added\n",
      "9 files from PIL added\n",
      "3 files from pip added\n",
      "94 files from platformdirs added\n",
      "52 files from pluggy added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satoru/projects/text-retrieval/my_project_env/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 files from prometheus_client added\n",
      "1332 files from prompt_toolkit added\n",
      "107 files from proto added\n",
      "48 files from google added\n",
      "243 files from psutil added\n",
      "80 files from psycopg2 added\n",
      "92 files from ptyprocess added\n",
      "16 files from pure_eval added\n",
      "1 files from py added\n",
      "2843 files from pyarrow added\n",
      "1 files from pyasn1 added\n",
      "1 files from pyasn1_modules added\n",
      "343 files from pycparser added\n",
      "136 files from pygments added\n",
      "97 files from jwt added\n",
      "1 files from OpenSSL added\n",
      "6736 files from pyparsing added\n",
      "337 files from pyrsistent added\n",
      "147 files from socks added\n",
      "64 files from sockshandler added\n",
      "71 files from pytest added\n",
      "145 files from dateutil added\n",
      "10 files from pytrec_eval added\n",
      "2 files from pytrec_eval_ext added\n",
      "71 files from pytz added\n",
      "2789 files from yaml added\n",
      "506 files from zmq added\n",
      "1 files from qtconsole added\n",
      "12 files from qtpy added\n",
      "42 files from regex added\n",
      "192 files from requests added\n",
      "114 files from requests_oauthlib added\n",
      "126 files from responses added\n",
      "61 files from rsa added\n",
      "213 files from s3fs added\n",
      "111 files from s3transfer added\n",
      "60 files from sacremoses added\n",
      "2710 files from sklearn added\n",
      "4083 files from scipy added\n",
      "1 files from selenium added\n",
      "11 files from send2trash added\n",
      "1614 files from sentence_transformers added\n",
      "189 files from sentencepiece added\n",
      "227 files from setuptools added\n",
      "64 files from six added\n",
      "2710 files from sklearn added\n",
      "6 files from sniffio added\n",
      "211 files from sortedcontainers added\n",
      "42 files from soupsieve added\n",
      "5090 files from sqlalchemy added\n",
      "60 files from sqlparse added\n",
      "119 files from stack_data added\n",
      "81 files from tabulate added\n",
      "89 files from tensorboard added\n",
      "3 files from tensorboard_data_server added\n",
      "1 files from tensorboard_plugin_wit added\n",
      "19532 files from tensorflow added\n",
      "15 files from tensorflow_estimator added\n",
      "121 files from tensorflow_io added\n",
      "--------------- error during tensorflow-io-gcs-filesystem documentation extracting\n",
      "5 files from termcolor added\n",
      "265 files from terminado added\n",
      "1 files from bin added\n",
      "--------------- error during theano documentation extracting\n",
      "76 files from threadpoolctl added\n",
      "21 files from tinycss2 added\n",
      "1 files from tk added\n",
      "923 files from tokenizers added\n",
      "116 files from toml added\n",
      "8 files from tomli added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satoru/projects/text-retrieval/my_project_env/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:181: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66157 files from torch added\n",
      "7591 files from torchvision added\n",
      "2 files from tornado added\n",
      "165 files from tqdm added\n",
      "1894 files from traitlets added\n",
      "370 files from trio added\n",
      "70 files from trio_websocket added\n",
      "158 files from typing added\n",
      "231 files from urllib3 added\n",
      "6 files from wcwidth added\n",
      "18 files from webencodings added\n",
      "155 files from websocket added\n",
      "330 files from werkzeug added\n",
      "1 files from wheel added\n",
      "2 files from widgetsnbextension added\n",
      "36 files from wrapt added\n",
      "33 files from wsproto added\n",
      "76 files from xxhash added\n",
      "66 files from yarl added\n",
      "86 files from zipp added\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>paths</th>\n",
       "      <th>library</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Library Documentation: Any in module tr...</td>\n",
       "      <td>[ipykernel.comm.Comm.log]</td>\n",
       "      <td>ipykernel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python Library Documentation: AxisProperty\\n\\n...</td>\n",
       "      <td>[pandas.DataFrame.columns]</td>\n",
       "      <td>pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Library Documentation: AxisProperty\\n\\n...</td>\n",
       "      <td>[pandas.Series.index]</td>\n",
       "      <td>pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Library Documentation: AxisProperty\\n\\n...</td>\n",
       "      <td>[pandas.DataFrame.index]</td>\n",
       "      <td>pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python Library Documentation: Bool in module o...</td>\n",
       "      <td>[openpyxl.chart.AreaChart.roundedCorners]</td>\n",
       "      <td>openpyxl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>Python Library Documentation: property\\n\\n    ...</td>\n",
       "      <td>[faiss.BufferList.wp]</td>\n",
       "      <td>faiss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>Python Library Documentation: reify\\n\\n</td>\n",
       "      <td>[aiohttp.ClientResponse.content_disposition]</td>\n",
       "      <td>aiohttp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>Python Library Documentation: reify\\n\\n    A s...</td>\n",
       "      <td>[aiohttp.ClientResponse.history]</td>\n",
       "      <td>aiohttp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>Python Library Documentation: reify\\n\\n    Ret...</td>\n",
       "      <td>[aiohttp.BodyPartReader.filename]</td>\n",
       "      <td>aiohttp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>Python Library Documentation: reify\\n\\n    Ret...</td>\n",
       "      <td>[aiohttp.BodyPartReader.name]</td>\n",
       "      <td>aiohttp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Python Library Documentation: Any in module tr...   \n",
       "1      Python Library Documentation: AxisProperty\\n\\n...   \n",
       "2      Python Library Documentation: AxisProperty\\n\\n...   \n",
       "3      Python Library Documentation: AxisProperty\\n\\n...   \n",
       "4      Python Library Documentation: Bool in module o...   \n",
       "...                                                  ...   \n",
       "30103  Python Library Documentation: property\\n\\n    ...   \n",
       "30104            Python Library Documentation: reify\\n\\n   \n",
       "30105  Python Library Documentation: reify\\n\\n    A s...   \n",
       "30106  Python Library Documentation: reify\\n\\n    Ret...   \n",
       "30107  Python Library Documentation: reify\\n\\n    Ret...   \n",
       "\n",
       "                                              paths    library  \n",
       "0                         [ipykernel.comm.Comm.log]  ipykernel  \n",
       "1                        [pandas.DataFrame.columns]     pandas  \n",
       "2                             [pandas.Series.index]     pandas  \n",
       "3                          [pandas.DataFrame.index]     pandas  \n",
       "4         [openpyxl.chart.AreaChart.roundedCorners]   openpyxl  \n",
       "...                                             ...        ...  \n",
       "30103                         [faiss.BufferList.wp]      faiss  \n",
       "30104  [aiohttp.ClientResponse.content_disposition]    aiohttp  \n",
       "30105              [aiohttp.ClientResponse.history]    aiohttp  \n",
       "30106             [aiohttp.BodyPartReader.filename]    aiohttp  \n",
       "30107                 [aiohttp.BodyPartReader.name]    aiohttp  \n",
       "\n",
       "[30108 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
